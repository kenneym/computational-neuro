{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compuational Neuroscience Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background:\n",
    "I spent my past summer working in the bioinformatics group of a small biotech company called Cell Signaling Technology. Our company focuses on the development of research antibodies, and much of the software I used involved structural modelling, binding-epitope prediction, binding-affinity prediction, etc. Many of these applications were built by implementing by pre-trained neural nets that could \"map\" antibody residue sequence to binding  site, structural features, etc.\n",
    "\n",
    "## Research Proposal:\n",
    "\n",
    "Although I used these machine-learning-based software packages, I've never done any actual machine learning coding myself. As a first step into machine learning, I attempted to perform a *somewhat* simple task involving antibody sequence processing:\n",
    "\n",
    "- Identify the species of an antibody, based on the nucleotide sequence of its light and heavy chains.\n",
    "\n",
    "It should be noted that there are no existing algorithms, to my knowledge, that attempt to identify the species from which an antibody sequence originated. This is probably because human researchers can do it pretty easily... nevertheless, I think this would be an interesting exercise. As inputs, I am considering looking into the features that Clusal Omega uses to determine sequence alignment, and seeing if using some of the insights from clustal omega could help build a more efficient neural net (to my untrained eye, testing the sequence alignment of two antibodies is the easiest way to see if they're part of the same species... two of the same species will often have ~%70 identity, whereas two of different species will often land around ~30-40% identity).\n",
    "\n",
    "## Objectives of this project\n",
    "\n",
    "- Prior to completing this project, I had never used any of the python libraries you see me using below. Thus, one of the most important objectives here was to begin introducing myself to machine learning through code, and to become familiar with some of the state-of-the-art libraries used to do that. I spent about 20-30 hours taking an udemy course, \"Complete Guide to TensorFlow for Deep Learning with Python\", and learned the basics of the following libraries:\n",
    "    - tensorflow\n",
    "    - pandas\n",
    "    - numpy\n",
    "    - scikitlearn\n",
    "    - matplotlib\n",
    "    \n",
    "- A second objective of this work was to become familiar with how exactly to apply a knowledge of machine learning to code itself- to translate a conceptual understanding into a technical skill. To some extent, I believe that I've made good progress in this area.\n",
    "\n",
    "- Thirdly, I hoped this project would give me a good understanding of how I might apply machine learning to real world data. In this case, I attempted to conjoin a domain-specific knowledge of antibody sequences and structure with a more general understanding of machine learning. Performing this exercise of combining my knowledge on a data set with a knowledge of machine learning will help me to reiterate this process on other forms of data in the time ahead of me. \n",
    "\n",
    "## Project\n",
    "\n",
    "The project itself was originally aimed at identifying the species of origin for an antibody sequence using sequencing data alone. However, because this is a fairly difficult task, and working with data such as images or sequence data requires a more technically complicated recurrent neural net, I've decided to break the project into two pieces.\n",
    "\n",
    "1. Identity the species of origin from which an antibody originated using a simple linear classifier or densely connected neural net, and continuous data points indicating various features about the antibody.\n",
    "\n",
    "2. Attempt to classify the antibody's species of origin using only sequencing information. Specifically, this sequence information will include the amino acid sequence of the antibody's light chain, and the sequences of the it's three complimentary determining regions.\n",
    "\n",
    "## Background\n",
    "\n",
    "Although additionally information about each of the above sub-projects will be provided further down in the code, in order to understand the intent behind the code, a little background on antibodies in general and their place in this project specifically is neccessary. To cover all my ground, I'm going to assume zero prior knowledge on the subject for anyone reviewing this ipython notebook.\n",
    "\n",
    "#### Antibodies Background:\n",
    "\n",
    "Antibodies(Ab), or immunoglobulins (Ig) are immune proteins, generated by nearly countless forms of species, ranging from mammals all the way back to cartilagenous fishes [Schluter et. al, 1977](https://www.ncbi.nlm.nih.gov/pubmed/9386351). In all cases, the primary function of an antibody is to attempt to bind to and neutralize pathogens. When an antibody binds to its target, it can perform one of two things:\n",
    "- Tag the protein, thus signaling the rest of the immune system of a potential intruder\n",
    "- Directly neutralize the target, in the case that the antibody has bound to an area on the pathogen that is biologically relevant and/or necessary for the pathogen's survival\n",
    "\n",
    "Antibodies thus form a critical piece of the body's immune system. The body develops antibodies in mass quantities to target a wide variety of pathogenic or potentially pathogenic proteins and ligands. By doing so, the body is typically able to create a subset of antibodies that can successfully bind to the non-native (or potentially pathogenic) protein that it is attempting to target. \n",
    "\n",
    "Further, once researchers realized the power of antibodies in the human body, they began to utilize antibodies for new tasks. Today, antibodies produced under the supervision of researchers from pharma, biotech, and academic research alike are used for a variety of tasks. Commercially produced antibodies now find therapeutic uses, and are especially useful for patients whose immune systems are not well-equipped to fight an ailment. Keytruda and Optivo, for example, use antibodies to fight a range of advanced cancers. In the case of cancer, the body's immune system does not often recognize cancer cells, causing the disease to spread. Antibody drugs can help to counteract this issue by triggering an immune response. Further, antibodies can be used in therapeutics to directly attack cancers or other pathogens by binding to a functionally critical location and performing neutralization directly. Finally, in addition to all of these therapeutics, antibodies can be used for research... for example, by enabling researchers to tag proteins they are studying in a tissue specimen with a florescent tag or a radioactive tag. These tags can help researchers to visualize and collect data on proteins they are studying.\n",
    "\n",
    "##### Structure\n",
    "\n",
    "To understand how exactly how the antibody has seen such enormous success, however, one has to take a look at its structure, and examine how the body introduces genetic variance. Antibodies express a unique Y-shape, as follows.\n",
    "\n",
    "![Antibody Shape](https://www.immunology.org/sites/default/files/Generation-of-B-cell-antibody-diversity-Figure-1.png)\n",
    "\n",
    "Taking a look at this Y shape, one can identify the various regions of an antibody. First of all, the antibody has two different \"chains\", meaning chains of ammino acid - the light chain and the heavy chain. Further, each of these chains can be broken down into two parts - the constant region, and the variable region. For a given antibody type, the constant region remains exactly the same. Two antibodies targeting entirely different pathogens will express the same constant regions nonetheless. The true power of the antibody, however, rests in the variable region- this is the region that actually binds to a target pathogen. \n",
    "\n",
    "To build the variable region, the body's B cells randomly pull from a gene pool in order to introduce genetic variance. The amino acid sequence of the variable region, therefore, is unique to each specific antibody. The body can generate virtually endless amino acid sequences in the varible region of the antibodies it produces; therefore, when these B cells are attempting to generate an antibody that can successfully bind a pathogen, they can merelly mass-produce antibodies, introducing genetic variance each time, until a successfully binding antibody emerges. Taking this approach results in an extremely high probability that the body can bind a given pathenogen.\n",
    "\n",
    "#### Application to Project\n",
    "\n",
    "Because of the genetic variance of these variable regions, there are no easy ways to perform any kind of analysis on them without data-driven techniques. In the case of this project, we will be feeding an algorithm only the sequence of the variable region of the antibody light chain. In addition, to provide a little extra data, we will be providing the algorithm data about the substructure of this light chain. To be more specific, all variable regions can be broken down into a couple different pieces, namely the complimentary-determining (CDR) regions, and the framework regions. The framework regions are more genetically stable than the CDR regions, so the CDR regions are really the  piece of the antibody that is primarily responsible for binding specificity. CDRs and framworks, in any given antibody, are always found in the antibody sequence in the following order:\n",
    "\n",
    "- Framework 1, CDR1, Framework 2, CDR2, Framework 3, CDR3, Framework 4\n",
    "\n",
    "Therefore, to provide the algorithm with additional data, we will be providing it the sequences of the CDR1,2, and 3 that form a piece of its variable light chain.\n",
    "\n",
    "In this project, we will be feeding the algorithm mouse and human antibody sequences only, and attempting to enable the algorithm to identity the species using this sequence data.\n",
    "\n",
    "Although this may seem like an impossible task, given the genetic variability/ randomness of the variable region, but keep in mind that each species is pulling from a different set of genes to create this variabilty. Therefore, across species, similar sequence motifs are expressed. Having this knowledge, we will attempt to see if our algorithm can identify some of these motifs, and make a distinction based on species.\n",
    "\n",
    "## Downfalls:\n",
    "\n",
    "1. The dataset I used, the Kabat antibody dataset, is from the late 1990s, and is formatted very poorly for usage in machine learning. In addition, there were numerous empty datafields, forcing me to cut my dataset to a mere 1000 sequences\n",
    "\n",
    "2. As a result of this, an unbelievable ammount of my code is pure data preparation, and my voyage into machine learning here is pretty unreasonable\n",
    "\n",
    "3. Currently, my reccurent neural net using sequence data alone cannot run... although I continue to work on getting it to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test efficacy of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:XLA_GPU:0', '/device:XLA_CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data to be used in this project derives from the Kabat sequence database, the largest database of antibody sequences by protein sequence. This dataset includes multiple species and approx. 50,000 entires... however, many of these entries include incomplete data. Further, the database is neither easy to find nor easy to work with.\n",
    "\n",
    "To simplify things, I've done some preprocessing on the database to attain the csv files you see below in this notebook, but will be leveraging the data formatting power of pandas to remove any incomplete entries, format columns etc.\n",
    "\n",
    "For the first machine learning task, I will be using the follow data points:\n",
    "\n",
    "- Length CDRL1\n",
    "- Length CDRL2\n",
    "- Length CDRL3\n",
    "- A given sequence's % identity match, on average, with other human antibody sequences\n",
    "- % identity match, on average, with other mouse antibody sequences\n",
    "- % identity of the sequence's best single match with any human antibody in our database\n",
    "- % identity of the sequence's best single match with any mouse antibody in our database\n",
    "\n",
    "In this inital machine learning task, I won't be using the actual antibody sequence data itself, as this would require a convolutional neural net and a little more code. We'll leave that for later. For now, all I'll be doing with the antibody light chain sequences is generating identity matrixes-- indicating how similar a given antibody chain is to the antibody chains coming from other species.\n",
    "\n",
    "In order for our algorithm to distinguish between species, it will only need to understand the relationship between species-specific sequence identity, and the length of the CDRs.\n",
    "\n",
    "Thus, for this task, all data entries lacking sequence or CDR length data will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/mouse_human.csv\",\"r\") as input:\n",
    "    with open(\"./data/mouse_human_data.csv\",\"w\") as output:\n",
    "        for line in input:\n",
    "            if not \"?\" in line and not \"X\" in line:\n",
    "                output.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv file\n",
    "mAbs = pd.read_csv('./data/mouse_human_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>LengthL1</th>\n",
       "      <th>LengthL2</th>\n",
       "      <th>LengthL3</th>\n",
       "      <th>Light</th>\n",
       "      <th>Heavy</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RASQSVSSSYLA</td>\n",
       "      <td>GASSRAT</td>\n",
       "      <td>QQYGSSPSIT</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYTFTSYAMHWVRQAPGQRLE...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGTSSDVGGYKYVS</td>\n",
       "      <td>DVTNRPS</td>\n",
       "      <td>SSYAGAQSLV</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASSTGAVTTGYYPN</td>\n",
       "      <td>STSNKHS</td>\n",
       "      <td>LLYYGGA</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYIHWVRQAPGQGLE...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KSSQSLLYSSNNKNYLA</td>\n",
       "      <td>WASTRES</td>\n",
       "      <td>QQYYSTPPM</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCEASGYTFTGHYMHWVGQAPGQGLE...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASQSIGSFLH</td>\n",
       "      <td>AASSLQS</td>\n",
       "      <td>QQSYSTLYT</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKTSGYTFVAYYVHWVRQAPGQGLQ...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  L1       L2          L3  LengthL1  LengthL2  LengthL3  \\\n",
       "0       RASQSVSSSYLA  GASSRAT  QQYGSSPSIT        12         7        10   \n",
       "1     TGTSSDVGGYKYVS  DVTNRPS  SSYAGAQSLV        14         7        10   \n",
       "2     ASSTGAVTTGYYPN  STSNKHS     LLYYGGA        14         7         7   \n",
       "3  KSSQSLLYSSNNKNYLA  WASTRES   QQYYSTPPM        17         7         9   \n",
       "4        RASQSIGSFLH  AASSLQS   QQSYSTLYT        11         7         9   \n",
       "\n",
       "                                               Light  \\\n",
       "0  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...   \n",
       "1  QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...   \n",
       "2  QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...   \n",
       "3  DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...   \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...   \n",
       "\n",
       "                                               Heavy Source  \n",
       "0  QVQLVQSGAEVKKPGASVKVSCKASGYTFTSYAMHWVRQAPGQRLE...  HUMAN  \n",
       "1  QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...  HUMAN  \n",
       "2  QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYIHWVRQAPGQGLE...  HUMAN  \n",
       "3  QVQLVQSGAEVKKPGASVKVSCEASGYTFTGHYMHWVGQAPGQGLE...  HUMAN  \n",
       "4  QVQLVQSGAEVKKPGASVKVSCKTSGYTFVAYYVHWVRQAPGQGLQ...  HUMAN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAbs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unneccessary Data Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAbs = mAbs.drop(['Heavy'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDR2s are always 7 residues in length across this entire dataset, as is extremely common for mouse and human antibodies. Therefore, this data point is not useful to us and should be dropped out as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAbs = mAbs.drop(['LengthL2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>LengthL1</th>\n",
       "      <th>LengthL3</th>\n",
       "      <th>Light</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RASQSVSSSYLA</td>\n",
       "      <td>GASSRAT</td>\n",
       "      <td>QQYGSSPSIT</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGTSSDVGGYKYVS</td>\n",
       "      <td>DVTNRPS</td>\n",
       "      <td>SSYAGAQSLV</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASSTGAVTTGYYPN</td>\n",
       "      <td>STSNKHS</td>\n",
       "      <td>LLYYGGA</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KSSQSLLYSSNNKNYLA</td>\n",
       "      <td>WASTRES</td>\n",
       "      <td>QQYYSTPPM</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASQSIGSFLH</td>\n",
       "      <td>AASSLQS</td>\n",
       "      <td>QQSYSTLYT</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...</td>\n",
       "      <td>HUMAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  L1       L2          L3  LengthL1  LengthL3  \\\n",
       "0       RASQSVSSSYLA  GASSRAT  QQYGSSPSIT        12        10   \n",
       "1     TGTSSDVGGYKYVS  DVTNRPS  SSYAGAQSLV        14        10   \n",
       "2     ASSTGAVTTGYYPN  STSNKHS     LLYYGGA        14         7   \n",
       "3  KSSQSLLYSSNNKNYLA  WASTRES   QQYYSTPPM        17         9   \n",
       "4        RASQSIGSFLH  AASSLQS   QQSYSTLYT        11         9   \n",
       "\n",
       "                                               Light Source  \n",
       "0  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...  HUMAN  \n",
       "1  QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...  HUMAN  \n",
       "2  QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...  HUMAN  \n",
       "3  DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...  HUMAN  \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...  HUMAN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1106"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mAbs.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Missing Data\n",
    "- Remove any entries without sequence data, using pandas dropna function\n",
    "(Missing entries default to Nan in pandas. Dropna removes any rows with missing entires)\n",
    "\n",
    "- Eliminate sequences with and CDR Lengths listed as zero, as this indicates missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAbs = mAbs.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAbs = mAbs[mAbs.LengthL1 != 0]\n",
    "mAbs = mAbs[mAbs.LengthL3 != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate fasta sequences for alignment later on:\n",
    " - Later in the generation of the dataset, we'll need to create a percentage identity matrix using a program called clustal omega. This information will enable us to determine how well a given antibody Fv sequence matches with sequences from other species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAbs['Light'].to_csv('./data/seqs', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_gen(sequence_file):\n",
    "    i = 0\n",
    "    out_file = sequence_file + \".fasta\"\n",
    "    with open(sequence_file,\"r\") as input:\n",
    "        with open(out_file,\"w\") as output:\n",
    "            for line in input:\n",
    "                line = \">sequence\" + str(i) + \"\\n\" + line\n",
    "                output.write(line)\n",
    "                i += 1\n",
    "    os.remove(sequence_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_gen('./data/seqs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the identity matrix and species similarity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next piece of data generation involes determining how similar a given sequence is to other sequences generated by its species. In order to assign a metric to each sequence for a dataset, indicating how similar it is to either the mouse species or the human species, we will use the following procedure:\n",
    "\n",
    "1. We have now generated a set of light chain sequences for every antibody in our dataset. Therefore, we are now able to use tools for fasta processing\n",
    "\n",
    "2. The tool clustal omega, a protein sequence alignment tool created by the European Bioinformatics Institute. The tool, if fed a fasta file of sequences, will individually align and compare each sequence in the file to every other sequence\n",
    "\n",
    "3. The tool is able to generate an identity matrix, where one sequence's similarity to another's is expressed as a %match (i.e. how many of the residues match between the two sequences after a proper alignment has been made. In this identity matrix, an percentage entry at row1 column5 indicates sequence 1's similiarity \n",
    "\n",
    "4. Because this tool is extremely computationally expensive, we are going to run the tool on a server I rented out on the cloud to perform this project. \n",
    "\n",
    "`clustalo --threads=$(nproc) --in seqs.fa --full --distmat-out=percents.csv --percent-id --out seq_identity`\n",
    "\n",
    "5. Percents file defaults to using spaces as the delimiter... convert the `percents` file into a true csv file using sed command to replace spaces with commas. Now we are ready to process with python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.fasta.fasta": ">sequence0\n--EIVLTQSPGTLSLSPGERATLSCRASQSVSSS---------YLAWYQQKPGQAPRLLI\nYG----ASSRATGIPDRFSGSGS--G--------TDFTLTISRLEPADFAVYYCQQYGS-\nS-P-SITFGQGTRLEIKR--\n>sequence1\n--QSVLTQ-PASVSGSPDQSITISCTGTSSDVGGY-------KYVSWYQQHPDKAPKVMI\nYD----VTNRPSGGSNRFSGSKS--G--------NTASLTISGLQAEDEADYYCSSYAGA\nQS-L-VFG-GGTKLTVLG--\n>sequence2\n--QTVVTQ-QPSLTVSPGGTVTLTCASSTGAVTTG-------YYPNWFQQKPGQAPRALI\nYS----TSNKHSWTPARFSGSLL--G--------GKAALTLSGVQPEDEAEYFCLLYYGG\nA-------------------\n>sequence3\n--DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNK----NYLAWYQQKPGQPPKLLI\nYW----ASTRESGVPDRFSGSGS--G--------TDFTLTISSLQAEDVAVYYCQQYYS-\nT-P--PMFGQGTKVEIKRT-\n>sequence4\n--DIQMTQSPSSLSASVGDRVTITCRASQ------SIG----SFLHWYQQKPGKGPKLLI\nSA----ASSLQSGVPSRFSGSGS--G--------TDFTLTISSLQPEDFATYYCQQSYST\n--L--YTFGQGTKLEIKR--\n>sequence5\n--EIVLTQSPGTLSLSPGERATLSCRASQSISSS---------FLAWYQQKVGQAPRLLI\nYG----ASSRATGIPDRFSGSGS--G--------TDFTLTISRLEPEDFAVYYCQQYGS-\nS-P--LTFGGGTKVEIKR--\n",
      "text/plain": [
       ">sequence0\n",
       "--EIVLTQSPGTLSLSPGERATLSCRASQSVSSS---------YLAWYQQKPGQAPRLLI\n",
       "YG----ASSRATGIPDRFSGSGS--G--------TDFTLTISRLEPADFAVYYCQQYGS-\n",
       "S-P-SITFGQGTRLEIKR--\n",
       ">sequence1\n",
       "--QSVLTQ-PASVSGSPDQSITISCTGTSSDVGGY-------KYVSWYQQHPDKAPKVMI\n",
       "YD----VTNRPSGGSNRFSGSKS--G--------NTASLTISGLQAEDEADYYCSSYAGA\n",
       "QS-L-VFG-GGTKLTVLG--\n",
       ">sequence2\n",
       "--QTVVTQ-QPSLTVSPGGTVTLTCASSTGAVTTG-------YYPNWFQQKPGQAPRALI\n",
       "YS----TSNKHSWTPARFSGSLL--G--------GKAALTLSGVQPEDEAEYFCLLYYGG\n",
       "A-------------------\n",
       ">sequence3\n",
       "--DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNK----NYLAWYQQKPGQPPKLLI\n",
       "YW----ASTRESGVPDRFSGSGS--G--------TDFTLTISSLQAEDVAVYYCQQYYS-\n",
       "T-P--PMFGQGTKVEIKRT-\n",
       ">sequence4\n",
       "--DIQMTQSPSSLSASVGDRVTITCRASQ------SIG----SFLHWYQQKPGKGPKLLI\n",
       "SA----ASSLQSGVPSRFSGSGS--G--------TDFTLTISSLQPEDFATYYCQQSYST\n",
       "--L--YTFGQGTKLEIKR--\n",
       ">sequence5\n",
       "--EIVLTQSPGTLSLSPGERATLSCRASQSISSS---------FLAWYQQKVGQAPRLLI\n",
       "YG----ASSRATGIPDRFSGSGS--G--------TDFTLTISRLEPEDFAVYYCQQYGS-\n",
       "S-P--LTFGGGTKVEIKR--\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To give you an idea of how clustal is aligning the sequences and assigns % identity\n",
    "# you can visualize how it introduces gaps to help align sequences.\n",
    "# Below are some of the sequences from our dataset that clustal aligned for us:\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def Fasta(data='f'):\n",
    "    bundle = {}\n",
    "    bundle['application/vnd.fasta.fasta'] = data\n",
    "    bundle['text/plain'] = data\n",
    "    display(bundle, raw=True)\n",
    "\n",
    "Fasta(\"\"\">sequence0\n",
    "--EIVLTQSPGTLSLSPGERATLSCRASQSVSSS---------YLAWYQQKPGQAPRLLI\n",
    "YG----ASSRATGIPDRFSGSGS--G--------TDFTLTISRLEPADFAVYYCQQYGS-\n",
    "S-P-SITFGQGTRLEIKR--\n",
    ">sequence1\n",
    "--QSVLTQ-PASVSGSPDQSITISCTGTSSDVGGY-------KYVSWYQQHPDKAPKVMI\n",
    "YD----VTNRPSGGSNRFSGSKS--G--------NTASLTISGLQAEDEADYYCSSYAGA\n",
    "QS-L-VFG-GGTKLTVLG--\n",
    ">sequence2\n",
    "--QTVVTQ-QPSLTVSPGGTVTLTCASSTGAVTTG-------YYPNWFQQKPGQAPRALI\n",
    "YS----TSNKHSWTPARFSGSLL--G--------GKAALTLSGVQPEDEAEYFCLLYYGG\n",
    "A-------------------\n",
    ">sequence3\n",
    "--DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNK----NYLAWYQQKPGQPPKLLI\n",
    "YW----ASTRESGVPDRFSGSGS--G--------TDFTLTISSLQAEDVAVYYCQQYYS-\n",
    "T-P--PMFGQGTKVEIKRT-\n",
    ">sequence4\n",
    "--DIQMTQSPSSLSASVGDRVTITCRASQ------SIG----SFLHWYQQKPGKGPKLLI\n",
    "SA----ASSLQSGVPSRFSGSGS--G--------TDFTLTISSLQPEDFATYYCQQSYST\n",
    "--L--YTFGQGTKLEIKR--\n",
    ">sequence5\n",
    "--EIVLTQSPGTLSLSPGERATLSCRASQSISSS---------FLAWYQQKVGQAPRLLI\n",
    "YG----ASSRATGIPDRFSGSGS--G--------TDFTLTISRLEPEDFAVYYCQQYGS-\n",
    "S-P--LTFGGGTKVEIKR--\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_matrix = np.array(list(csv.reader(open(\"./data/percents.csv\", \"r\"), delimiter=\",\"))).astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to percentages only, then change string representation of values to floats\n",
    "id_matrix = id_matrix[:,1:].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106, 1106)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_matrix.shape\n",
    "# Extra column comes from the sequence name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First entries in database are human. Get number of entries for demonstration\n",
    "len(mAbs[mAbs.Source == 'HUMAN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_humans = len(mAbs[mAbs.Source == 'HUMAN'])\n",
    "num_mice = len(mAbs[mAbs.Source == 'MOUSE'])\n",
    "matches = open('./data/matches.csv','w')\n",
    "\n",
    "matches.write(\"Avg-Human-Match,Best-Human-Match,Avg-Mouse-Match,Best-Mouse-Match\\n\")\n",
    "\n",
    "for i in range(0,np.shape(id_matrix)[0]):\n",
    "    \n",
    "    human_match = 0\n",
    "    mouse_match = 0\n",
    "    best_human_match = 0\n",
    "    best_mouse_match = 0\n",
    "    \n",
    "    for j in range(0,np.shape(id_matrix)[1]):\n",
    "        \n",
    "        if j < num_humans and id_matrix.item((i,j)) != 100.0 :\n",
    "            human_match += id_matrix.item((i,j))\n",
    "            \n",
    "            if id_matrix.item((i,j)) > best_human_match:\n",
    "                best_human_match = id_matrix.item((i,j))\n",
    "            \n",
    "        \n",
    "        elif id_matrix.item((i,j)) != 100 :\n",
    "            mouse_match += id_matrix.item((i,j))\n",
    "            \n",
    "            if id_matrix.item((i,j)) > best_mouse_match:\n",
    "                best_mouse_match = id_matrix.item((i,j))\n",
    "            \n",
    "    human_match /= num_humans -1 \n",
    "    mouse_match /= num_mice -1 \n",
    "        \n",
    "    matches.write(str(human_match) + \",\" + str(best_human_match) + \",\" + \\\n",
    "                  str(mouse_match) + \",\" + str(best_mouse_match) + '\\n')\n",
    "\n",
    "matches.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_vals = pd.read_csv('./data/matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add everything into prexisting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAbs['AvgHumanMatch'] = match_vals['Avg-Human-Match']\n",
    "mAbs['BestHumanMatch'] = match_vals['Best-Human-Match']\n",
    "mAbs['AvgMouseMatch'] = match_vals['Avg-Mouse-Match']\n",
    "mAbs['BestMouseMatch'] = match_vals['Best-Mouse-Match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>LengthL1</th>\n",
       "      <th>LengthL3</th>\n",
       "      <th>Light</th>\n",
       "      <th>Source</th>\n",
       "      <th>AvgHumanMatch</th>\n",
       "      <th>BestHumanMatch</th>\n",
       "      <th>AvgMouseMatch</th>\n",
       "      <th>BestMouseMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RASQSVSSSYLA</td>\n",
       "      <td>GASSRAT</td>\n",
       "      <td>QQYGSSPSIT</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>58.033865</td>\n",
       "      <td>98.958333</td>\n",
       "      <td>54.246754</td>\n",
       "      <td>66.972477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGTSSDVGGYKYVS</td>\n",
       "      <td>DVTNRPS</td>\n",
       "      <td>SSYAGAQSLV</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>44.926556</td>\n",
       "      <td>87.387387</td>\n",
       "      <td>35.748652</td>\n",
       "      <td>44.036697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASSTGAVTTGYYPN</td>\n",
       "      <td>STSNKHS</td>\n",
       "      <td>LLYYGGA</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>38.934404</td>\n",
       "      <td>62.886598</td>\n",
       "      <td>36.799879</td>\n",
       "      <td>60.824742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KSSQSLLYSSNNKNYLA</td>\n",
       "      <td>WASTRES</td>\n",
       "      <td>QQYYSTPPM</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>58.445212</td>\n",
       "      <td>98.260870</td>\n",
       "      <td>59.885397</td>\n",
       "      <td>83.185841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASQSIGSFLH</td>\n",
       "      <td>AASSLQS</td>\n",
       "      <td>QQSYSTLYT</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>60.007143</td>\n",
       "      <td>92.523364</td>\n",
       "      <td>60.291405</td>\n",
       "      <td>78.703704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  L1       L2          L3  LengthL1  LengthL3  \\\n",
       "0       RASQSVSSSYLA  GASSRAT  QQYGSSPSIT        12        10   \n",
       "1     TGTSSDVGGYKYVS  DVTNRPS  SSYAGAQSLV        14        10   \n",
       "2     ASSTGAVTTGYYPN  STSNKHS     LLYYGGA        14         7   \n",
       "3  KSSQSLLYSSNNKNYLA  WASTRES   QQYYSTPPM        17         9   \n",
       "4        RASQSIGSFLH  AASSLQS   QQSYSTLYT        11         9   \n",
       "\n",
       "                                               Light Source  AvgHumanMatch  \\\n",
       "0  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...  HUMAN      58.033865   \n",
       "1  QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...  HUMAN      44.926556   \n",
       "2  QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...  HUMAN      38.934404   \n",
       "3  DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...  HUMAN      58.445212   \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...  HUMAN      60.007143   \n",
       "\n",
       "   BestHumanMatch  AvgMouseMatch  BestMouseMatch  \n",
       "0       98.958333      54.246754       66.972477  \n",
       "1       87.387387      35.748652       44.036697  \n",
       "2       62.886598      36.799879       60.824742  \n",
       "3       98.260870      59.885397       83.185841  \n",
       "4       92.523364      60.291405       78.703704  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAbs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data types into correct format:\n",
    "- String representations of numerical values -> floats\n",
    "- Source to a binary representation, either 1 for 0, where 1 is human, and 0 is mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_float = ['LengthL1','LengthL3','AvgHumanMatch','AvgMouseMatch','BestHumanMatch','BestMouseMatch']\n",
    "mAbs[cols_to_float] = mAbs[cols_to_float].astype(float)\n",
    "\n",
    "# Convert species classifications to learnable output:\n",
    "mAbs['Source'] = mAbs['Source'].apply(lambda label: int(label == 'HUMAN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>LengthL1</th>\n",
       "      <th>LengthL3</th>\n",
       "      <th>Light</th>\n",
       "      <th>Source</th>\n",
       "      <th>AvgHumanMatch</th>\n",
       "      <th>BestHumanMatch</th>\n",
       "      <th>AvgMouseMatch</th>\n",
       "      <th>BestMouseMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RASQSVSSSYLA</td>\n",
       "      <td>GASSRAT</td>\n",
       "      <td>QQYGSSPSIT</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>1</td>\n",
       "      <td>58.033865</td>\n",
       "      <td>98.958333</td>\n",
       "      <td>54.246754</td>\n",
       "      <td>66.972477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGTSSDVGGYKYVS</td>\n",
       "      <td>DVTNRPS</td>\n",
       "      <td>SSYAGAQSLV</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...</td>\n",
       "      <td>1</td>\n",
       "      <td>44.926556</td>\n",
       "      <td>87.387387</td>\n",
       "      <td>35.748652</td>\n",
       "      <td>44.036697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASSTGAVTTGYYPN</td>\n",
       "      <td>STSNKHS</td>\n",
       "      <td>LLYYGGA</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.934404</td>\n",
       "      <td>62.886598</td>\n",
       "      <td>36.799879</td>\n",
       "      <td>60.824742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KSSQSLLYSSNNKNYLA</td>\n",
       "      <td>WASTRES</td>\n",
       "      <td>QQYYSTPPM</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...</td>\n",
       "      <td>1</td>\n",
       "      <td>58.445212</td>\n",
       "      <td>98.260870</td>\n",
       "      <td>59.885397</td>\n",
       "      <td>83.185841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASQSIGSFLH</td>\n",
       "      <td>AASSLQS</td>\n",
       "      <td>QQSYSTLYT</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...</td>\n",
       "      <td>1</td>\n",
       "      <td>60.007143</td>\n",
       "      <td>92.523364</td>\n",
       "      <td>60.291405</td>\n",
       "      <td>78.703704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  L1       L2          L3  LengthL1  LengthL3  \\\n",
       "0       RASQSVSSSYLA  GASSRAT  QQYGSSPSIT      12.0      10.0   \n",
       "1     TGTSSDVGGYKYVS  DVTNRPS  SSYAGAQSLV      14.0      10.0   \n",
       "2     ASSTGAVTTGYYPN  STSNKHS     LLYYGGA      14.0       7.0   \n",
       "3  KSSQSLLYSSNNKNYLA  WASTRES   QQYYSTPPM      17.0       9.0   \n",
       "4        RASQSIGSFLH  AASSLQS   QQSYSTLYT      11.0       9.0   \n",
       "\n",
       "                                               Light  Source  AvgHumanMatch  \\\n",
       "0  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...       1      58.033865   \n",
       "1  QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...       1      44.926556   \n",
       "2  QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...       1      38.934404   \n",
       "3  DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...       1      58.445212   \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...       1      60.007143   \n",
       "\n",
       "   BestHumanMatch  AvgMouseMatch  BestMouseMatch  \n",
       "0       98.958333      54.246754       66.972477  \n",
       "1       87.387387      35.748652       44.036697  \n",
       "2       62.886598      36.799879       60.824742  \n",
       "3       98.260870      59.885397       83.185841  \n",
       "4       92.523364      60.291405       78.703704  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAbs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform normalization:\n",
    "- In order to prevent any of our data points from having an undue influence on our model, we will now\n",
    "normalize each of the data points.\n",
    "- Since the percentage values are significantly different in magnitude than the CDR length values, a normalization is neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_normalize = ['LengthL1','LengthL3','AvgHumanMatch','AvgMouseMatch','BestHumanMatch','BestMouseMatch']\n",
    "mAbs[cols_to_normalize] = mAbs[cols_to_normalize].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>LengthL1</th>\n",
       "      <th>LengthL3</th>\n",
       "      <th>Light</th>\n",
       "      <th>Source</th>\n",
       "      <th>AvgHumanMatch</th>\n",
       "      <th>BestHumanMatch</th>\n",
       "      <th>AvgMouseMatch</th>\n",
       "      <th>BestMouseMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RASQSVSSSYLA</td>\n",
       "      <td>GASSRAT</td>\n",
       "      <td>QQYGSSPSIT</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833534</td>\n",
       "      <td>0.996809</td>\n",
       "      <td>0.746740</td>\n",
       "      <td>0.470002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGTSSDVGGYKYVS</td>\n",
       "      <td>DVTNRPS</td>\n",
       "      <td>SSYAGAQSLV</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377655</td>\n",
       "      <td>0.761221</td>\n",
       "      <td>0.166577</td>\n",
       "      <td>0.091906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASSTGAVTTGYYPN</td>\n",
       "      <td>STSNKHS</td>\n",
       "      <td>LLYYGGA</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169244</td>\n",
       "      <td>0.262376</td>\n",
       "      <td>0.199547</td>\n",
       "      <td>0.368657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KSSQSLLYSSNNKNYLA</td>\n",
       "      <td>WASTRES</td>\n",
       "      <td>QQYYSTPPM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847841</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.923587</td>\n",
       "      <td>0.737279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASQSIGSFLH</td>\n",
       "      <td>AASSLQS</td>\n",
       "      <td>QQSYSTLYT</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902165</td>\n",
       "      <td>0.865791</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>0.663391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  L1       L2          L3  LengthL1  LengthL3  \\\n",
       "0       RASQSVSSSYLA  GASSRAT  QQYGSSPSIT  0.285714  0.727273   \n",
       "1     TGTSSDVGGYKYVS  DVTNRPS  SSYAGAQSLV  0.571429  0.727273   \n",
       "2     ASSTGAVTTGYYPN  STSNKHS     LLYYGGA  0.571429  0.454545   \n",
       "3  KSSQSLLYSSNNKNYLA  WASTRES   QQYYSTPPM  1.000000  0.636364   \n",
       "4        RASQSIGSFLH  AASSLQS   QQSYSTLYT  0.142857  0.636364   \n",
       "\n",
       "                                               Light  Source  AvgHumanMatch  \\\n",
       "0  EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPR...       1       0.833534   \n",
       "1  QSVLTQPASVSGSPDQSITISCTGTSSDVGGYKYVSWYQQHPDKAP...       1       0.377655   \n",
       "2  QTVVTQQPSLTVSPGGTVTLTCASSTGAVTTGYYPNWFQQKPGQAP...       1       0.169244   \n",
       "3  DIVMTQSPDSLAVSLGERATINCKSSQSLLYSSNNKNYLAWYQQKP...       1       0.847841   \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQSIGSFLHWYQQKPGKGPKL...       1       0.902165   \n",
       "\n",
       "   BestHumanMatch  AvgMouseMatch  BestMouseMatch  \n",
       "0        0.996809       0.746740        0.470002  \n",
       "1        0.761221       0.166577        0.091906  \n",
       "2        0.262376       0.199547        0.368657  \n",
       "3        0.982609       0.923587        0.737279  \n",
       "4        0.865791       0.936321        0.663391  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAbs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Sequence values until later\n",
    "Since we won't actually be using the sequences themselves, we'll drop these out of the dataset for now, and store them for later in case we have time to run a convolutional neural net that takes sequence data in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mAbs= mAbs\n",
    "mAbs = mAbs.drop(['L1','L2','L3','Light'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LengthL1</th>\n",
       "      <th>LengthL3</th>\n",
       "      <th>Source</th>\n",
       "      <th>AvgHumanMatch</th>\n",
       "      <th>BestHumanMatch</th>\n",
       "      <th>AvgMouseMatch</th>\n",
       "      <th>BestMouseMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833534</td>\n",
       "      <td>0.996809</td>\n",
       "      <td>0.746740</td>\n",
       "      <td>0.470002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377655</td>\n",
       "      <td>0.761221</td>\n",
       "      <td>0.166577</td>\n",
       "      <td>0.091906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169244</td>\n",
       "      <td>0.262376</td>\n",
       "      <td>0.199547</td>\n",
       "      <td>0.368657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847841</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.923587</td>\n",
       "      <td>0.737279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902165</td>\n",
       "      <td>0.865791</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>0.663391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LengthL1  LengthL3  Source  AvgHumanMatch  BestHumanMatch  AvgMouseMatch  \\\n",
       "0  0.285714  0.727273       1       0.833534        0.996809       0.746740   \n",
       "1  0.571429  0.727273       1       0.377655        0.761221       0.166577   \n",
       "2  0.571429  0.454545       1       0.169244        0.262376       0.199547   \n",
       "3  1.000000  0.636364       1       0.847841        0.982609       0.923587   \n",
       "4  0.142857  0.636364       1       0.902165        0.865791       0.936321   \n",
       "\n",
       "   BestMouseMatch  \n",
       "0        0.470002  \n",
       "1        0.091906  \n",
       "2        0.368657  \n",
       "3        0.737279  \n",
       "4        0.663391  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAbs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a train-test split\n",
    "- Use approx. 30% of the training data\n",
    "- The train test split algorithm from scikitlearn will randomize the data order for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x values for our net\n",
    "x_data = mAbs.drop('Source', axis = 1)\n",
    "\n",
    "# t values for our net\n",
    "y_labels = mAbs['Source']\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous feature columns\n",
    "len_l1 = tf.feature_column.numeric_column(\"LengthL1\")\n",
    "len_l3 = tf.feature_column.numeric_column(\"LengthL3\")\n",
    "avg_human_match  = tf.feature_column.numeric_column(\"AvgHumanMatch\")\n",
    "avg_mouse_match  = tf.feature_column.numeric_column(\"AvgMouseMatch\")\n",
    "best_human_match = tf.feature_column.numeric_column(\"BestHumanMatch\")\n",
    "best_mouse_match = tf.feature_column.numeric_column(\"BestMouseMatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [len_l1,len_l3,avg_human_match,avg_mouse_match,best_human_match,best_mouse_match]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Model\n",
    "- At this point in time, we have all of the data we need to generate the model\n",
    "- Tensorflow will abstract the majority of this process for us, and we will be using a simple densely connected Neural Net from the tensorflow estimator class to complete the process.\n",
    "- According to [Keskar et. al. 2016](https://arxiv.org/abs/1609.04836), large batch sizes tend to lead to poor generalization of the model. The reasons behind this phenomena are somewhat unclear, but the truth remains nonetheless. Reccomended batch size is typically around 32 points for a dataset of around 1000 points, like the one we are using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=32, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp2_aowfrt\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp2_aowfrt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0594a63fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns=feature_cols,n_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/paperspace/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/paperspace/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp2_aowfrt/model.ckpt.\n",
      "INFO:tensorflow:loss = 22.18071, step = 0\n",
      "INFO:tensorflow:global_step/sec: 283.986\n",
      "INFO:tensorflow:loss = 10.510522, step = 100 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.78\n",
      "INFO:tensorflow:loss = 8.064489, step = 200 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.273\n",
      "INFO:tensorflow:loss = 6.0913925, step = 300 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.439\n",
      "INFO:tensorflow:loss = 6.816, step = 400 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.587\n",
      "INFO:tensorflow:loss = 9.491072, step = 500 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.891\n",
      "INFO:tensorflow:loss = 4.394574, step = 600 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.957\n",
      "INFO:tensorflow:loss = 5.0428753, step = 700 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.097\n",
      "INFO:tensorflow:loss = 4.3534393, step = 800 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.289\n",
      "INFO:tensorflow:loss = 4.518978, step = 900 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.49\n",
      "INFO:tensorflow:loss = 3.7469814, step = 1000 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.852\n",
      "INFO:tensorflow:loss = 2.8205366, step = 1100 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.928\n",
      "INFO:tensorflow:loss = 2.0721283, step = 1200 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.811\n",
      "INFO:tensorflow:loss = 2.853236, step = 1300 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.427\n",
      "INFO:tensorflow:loss = 6.122291, step = 1400 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.874\n",
      "INFO:tensorflow:loss = 4.75564, step = 1500 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.219\n",
      "INFO:tensorflow:loss = 4.747285, step = 1600 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.122\n",
      "INFO:tensorflow:loss = 5.121502, step = 1700 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.566\n",
      "INFO:tensorflow:loss = 3.6968415, step = 1800 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.296\n",
      "INFO:tensorflow:loss = 2.2616243, step = 1900 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.187\n",
      "INFO:tensorflow:loss = 4.6242075, step = 2000 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.097\n",
      "INFO:tensorflow:loss = 2.338283, step = 2100 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.783\n",
      "INFO:tensorflow:loss = 3.7495086, step = 2200 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.614\n",
      "INFO:tensorflow:loss = 1.6255016, step = 2300 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.135\n",
      "INFO:tensorflow:loss = 4.232906, step = 2400 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.192\n",
      "INFO:tensorflow:loss = 2.4536219, step = 2500 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.713\n",
      "INFO:tensorflow:loss = 7.5565963, step = 2600 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.801\n",
      "INFO:tensorflow:loss = 1.6366647, step = 2700 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.509\n",
      "INFO:tensorflow:loss = 2.7783563, step = 2800 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.038\n",
      "INFO:tensorflow:loss = 4.4821815, step = 2900 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.137\n",
      "INFO:tensorflow:loss = 2.7351623, step = 3000 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.464\n",
      "INFO:tensorflow:loss = 5.611305, step = 3100 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.538\n",
      "INFO:tensorflow:loss = 2.521923, step = 3200 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.585\n",
      "INFO:tensorflow:loss = 6.956201, step = 3300 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.887\n",
      "INFO:tensorflow:loss = 2.3887784, step = 3400 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.507\n",
      "INFO:tensorflow:loss = 4.8761683, step = 3500 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.453\n",
      "INFO:tensorflow:loss = 4.083148, step = 3600 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.668\n",
      "INFO:tensorflow:loss = 2.8260775, step = 3700 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.147\n",
      "INFO:tensorflow:loss = 2.2386189, step = 3800 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.052\n",
      "INFO:tensorflow:loss = 5.6422853, step = 3900 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.119\n",
      "INFO:tensorflow:loss = 6.967191, step = 4000 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.863\n",
      "INFO:tensorflow:loss = 3.4920852, step = 4100 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.91\n",
      "INFO:tensorflow:loss = 2.7481084, step = 4200 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.059\n",
      "INFO:tensorflow:loss = 9.988306, step = 4300 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.184\n",
      "INFO:tensorflow:loss = 1.6919768, step = 4400 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.589\n",
      "INFO:tensorflow:loss = 2.1110163, step = 4500 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.991\n",
      "INFO:tensorflow:loss = 10.257556, step = 4600 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.717\n",
      "INFO:tensorflow:loss = 1.3140625, step = 4700 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.523\n",
      "INFO:tensorflow:loss = 2.3120973, step = 4800 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.111\n",
      "INFO:tensorflow:loss = 7.3143134, step = 4900 (0.268 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp2_aowfrt/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.4288125.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f0594a63b00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      y=y_test,\n",
    "      batch_size=32,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-13-00:21:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2_aowfrt/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-13-00:21:35\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9698795, accuracy_baseline = 0.6415663, auc = 0.980116, auc_precision_recall = 0.9785545, average_loss = 0.12527862, global_step = 5000, label/mean = 0.35843372, loss = 3.7811365, precision = 0.9823009, prediction/mean = 0.35246143, recall = 0.9327731\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp2_aowfrt/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9698795,\n",
       " 'accuracy_baseline': 0.6415663,\n",
       " 'auc': 0.980116,\n",
       " 'auc_precision_recall': 0.9785545,\n",
       " 'average_loss': 0.12527862,\n",
       " 'label/mean': 0.35843372,\n",
       " 'loss': 3.7811365,\n",
       " 'precision': 0.9823009,\n",
       " 'prediction/mean': 0.35246143,\n",
       " 'recall': 0.9327731,\n",
       " 'global_step': 5000}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Deprivation\n",
    "Seeing now that the problem was extremely easy for the algorithm to solve, we will remove one of the feature columns and see if this changes our results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [len_l1,len_l3,avg_human_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=32, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpn3w1e54b\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpn3w1e54b', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f058fc3a208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns=feature_cols,n_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpn3w1e54b/model.ckpt.\n",
      "INFO:tensorflow:loss = 22.18071, step = 0\n",
      "INFO:tensorflow:global_step/sec: 320.701\n",
      "INFO:tensorflow:loss = 21.761436, step = 100 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.066\n",
      "INFO:tensorflow:loss = 19.59744, step = 200 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.487\n",
      "INFO:tensorflow:loss = 20.346792, step = 300 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.936\n",
      "INFO:tensorflow:loss = 21.354244, step = 400 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.38\n",
      "INFO:tensorflow:loss = 18.169449, step = 500 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.72\n",
      "INFO:tensorflow:loss = 16.720913, step = 600 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.855\n",
      "INFO:tensorflow:loss = 17.695124, step = 700 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.654\n",
      "INFO:tensorflow:loss = 19.846851, step = 800 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.675\n",
      "INFO:tensorflow:loss = 17.985939, step = 900 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.193\n",
      "INFO:tensorflow:loss = 16.841259, step = 1000 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.424\n",
      "INFO:tensorflow:loss = 20.141792, step = 1100 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.112\n",
      "INFO:tensorflow:loss = 24.313427, step = 1200 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.981\n",
      "INFO:tensorflow:loss = 21.06752, step = 1300 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.618\n",
      "INFO:tensorflow:loss = 17.672995, step = 1400 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.54\n",
      "INFO:tensorflow:loss = 18.587955, step = 1500 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.095\n",
      "INFO:tensorflow:loss = 15.744647, step = 1600 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.209\n",
      "INFO:tensorflow:loss = 20.405388, step = 1700 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.582\n",
      "INFO:tensorflow:loss = 17.619892, step = 1800 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.92\n",
      "INFO:tensorflow:loss = 17.454117, step = 1900 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.828\n",
      "INFO:tensorflow:loss = 24.08725, step = 2000 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.292\n",
      "INFO:tensorflow:loss = 19.015047, step = 2100 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.686\n",
      "INFO:tensorflow:loss = 21.767921, step = 2200 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.753\n",
      "INFO:tensorflow:loss = 18.888096, step = 2300 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.508\n",
      "INFO:tensorflow:loss = 19.337215, step = 2400 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.521\n",
      "INFO:tensorflow:loss = 20.244764, step = 2500 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.537\n",
      "INFO:tensorflow:loss = 18.83995, step = 2600 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.615\n",
      "INFO:tensorflow:loss = 18.71796, step = 2700 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.217\n",
      "INFO:tensorflow:loss = 21.661419, step = 2800 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.84\n",
      "INFO:tensorflow:loss = 19.655376, step = 2900 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.818\n",
      "INFO:tensorflow:loss = 19.767761, step = 3000 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.82\n",
      "INFO:tensorflow:loss = 17.628532, step = 3100 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.897\n",
      "INFO:tensorflow:loss = 18.29571, step = 3200 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.339\n",
      "INFO:tensorflow:loss = 16.682617, step = 3300 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.734\n",
      "INFO:tensorflow:loss = 18.919477, step = 3400 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.103\n",
      "INFO:tensorflow:loss = 16.696983, step = 3500 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.698\n",
      "INFO:tensorflow:loss = 19.561008, step = 3600 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.014\n",
      "INFO:tensorflow:loss = 16.998016, step = 3700 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.229\n",
      "INFO:tensorflow:loss = 18.555138, step = 3800 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.84\n",
      "INFO:tensorflow:loss = 18.356606, step = 3900 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.59\n",
      "INFO:tensorflow:loss = 16.81826, step = 4000 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.249\n",
      "INFO:tensorflow:loss = 16.231796, step = 4100 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.657\n",
      "INFO:tensorflow:loss = 20.430975, step = 4200 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.685\n",
      "INFO:tensorflow:loss = 15.239935, step = 4300 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.657\n",
      "INFO:tensorflow:loss = 18.59663, step = 4400 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.414\n",
      "INFO:tensorflow:loss = 20.64355, step = 4500 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.384\n",
      "INFO:tensorflow:loss = 20.081299, step = 4600 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.929\n",
      "INFO:tensorflow:loss = 20.650143, step = 4700 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.552\n",
      "INFO:tensorflow:loss = 14.68097, step = 4800 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.235\n",
      "INFO:tensorflow:loss = 17.162868, step = 4900 (0.259 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpn3w1e54b/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15.768019.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f058fc3a320>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      y=y_test,\n",
    "      batch_size=32,\n",
    "      num_epochs=1,    \n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-13-00:22:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpn3w1e54b/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-13-00:22:03\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.77710843, accuracy_baseline = 0.6415663, auc = 0.67341304, auc_precision_recall = 0.683409, average_loss = 0.59404254, global_step = 5000, label/mean = 0.35843372, loss = 17.929283, precision = 0.9245283, prediction/mean = 0.36948937, recall = 0.4117647\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpn3w1e54b/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.77710843,\n",
       " 'accuracy_baseline': 0.6415663,\n",
       " 'auc': 0.67341304,\n",
       " 'auc_precision_recall': 0.683409,\n",
       " 'average_loss': 0.59404254,\n",
       " 'label/mean': 0.35843372,\n",
       " 'loss': 17.929283,\n",
       " 'precision': 0.9245283,\n",
       " 'prediction/mean': 0.36948937,\n",
       " 'recall': 0.4117647,\n",
       " 'global_step': 5000}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt Classification Based on CDRs and Sequence Data alone:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format\n",
    "\n",
    "The format required by the pysster program involves a simply formated fasta file in which the top sequence:\n",
    "- `fasta header`\n",
    "- `sequence`\n",
    "- `annotations for sequence`\n",
    "\n",
    "For example, an example sequence provided in pysster's example usage documents is as follows:\n",
    "\n",
    ">\\>chr12:96402325-96402626(+)\n",
    "UUUUUUUUUUUAAGAGUUAAGAAGCAAGAAAAAUCAGGAUUAAUGCCUUCAACAUCAAUUUUUCCCCCCAUAAAACUUAAUUUUCUAGGCUGGGCACAGUGGCUCAUGCCUGAUGCCUGUAAUUCCAGCACUUUGGGAGGCUAAGGUGGGAGGAUCACUGGAGACCAGGAGUUUGAGACCAGCCUGUACAACACAGACCCUGUUUGUAUAAAAAGUUUUAAAUUAGCCAGGCAUGGAGGCACAUGCCUGUAGUCCCAGUUACUCGGGAGGCUGAGGUGGGACAACUGACUGAGCCCAGGAG\n",
    "FFFFFFFFFFFFSSSSSSSSSIIIIIIIIIIIIIISSSSSSISSSHHHHHHHSSSISSSSSSIIIIIIIIIIIIISSSSSSSSSMMMMMSSSSSSISSSSSSSHHHHSSSMMMMMSSSSIIISSSSSSSSSSSSSSHHHHSSSSSSSSIIIIIIIIISSSSSSIISSSSSSSSSSSSSSIIIIISSSSSSSISSSSHHHSSSSSSSSSSSIIIISSSSSSSSSSMMMSSSSSSSSHHHHHHSSSSSSSSMMSSSSSSIIIISSSSSHHHHSSSSSISSSSSSMMMMMSSSSISSSSSSTTT\n",
    "\n",
    "In the above example, the first line is a name of an RNA sequence, the second line indicates the RNA sequence itself, and the thrid line indicates the structural category into which each subset of RNA fits (secondary structure of the RNA sequence).\n",
    "\n",
    "\n",
    "## Defining Our Alphabet\n",
    "\n",
    "In pysster, arbitrary alphabets may be defined in order to define any attribute of your sequence. In our case, all of our sequences follow the same pattern:\n",
    "\n",
    "`Framework 1, CDR1, Framework 2, CDR2, Framework3, CDR3, Framework 4.`\n",
    "\n",
    "\n",
    "Therefore, our arbitrarily defined alphabet will define these areas of each sequence as such. To indacte them, we will use the alphabet:\n",
    "\n",
    "`A,1,B,2,C,3,D`\n",
    "\n",
    "where letters indicate frameworks and numbers indicate CDR regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGTSSDVGGYKYVS\n"
     ]
    }
   ],
   "source": [
    "print(full_mAbs.iloc[1].L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 36\n"
     ]
    }
   ],
   "source": [
    "start = full_mAbs.iloc[1].Light.find(full_mAbs.iloc[1].L1)\n",
    "end = start + len(full_mAbs.iloc[1].L1)\n",
    "print(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(full_mAbs.iloc[1].L1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(fasta_in,fasta_out):\n",
    "    i = 0\n",
    "    with open(fasta_in,'r') as input:\n",
    "        with open(fasta_out,\"w\") as output:\n",
    "            for line in input:\n",
    "\n",
    "                output_line = line\n",
    "                annotation = ''\n",
    "\n",
    "                # Only perform annotation if we are actually looking at the data file\n",
    "                if 'sequence' not in line:\n",
    "                    start_cdr1 = full_mAbs.iloc[i].Light.find(full_mAbs.iloc[i].L1)\n",
    "                    end_cdr1 = start_cdr1 + len(full_mAbs.iloc[i].L1)\n",
    "                    start_cdr2 = full_mAbs.iloc[i].Light.find(full_mAbs.iloc[i].L2)\n",
    "                    end_cdr2 = start_cdr2 + len(full_mAbs.iloc[i].L2)\n",
    "                    start_cdr3 = full_mAbs.iloc[i].Light.find(full_mAbs.iloc[i].L3)\n",
    "                    end_cdr3 = start_cdr3 + len(full_mAbs.iloc[i].L3)                \n",
    "\n",
    "                    # Framework 1:\n",
    "                    f1 = (start_cdr1) * 'a'\n",
    "                    cdr1 = (end_cdr1 - start_cdr1) * '1'\n",
    "                    f2 = (start_cdr2 - end_cdr1) * 'b'\n",
    "                    cdr2 = (end_cdr2 - start_cdr2) * '2'\n",
    "                    f3 = (start_cdr3- end_cdr2) * 'c'\n",
    "                    cdr3 = (end_cdr3 - start_cdr3) * '3'\n",
    "                    f4 = (len(full_mAbs.iloc[i].Light) - end_cdr3) * 'd'\n",
    "\n",
    "                    annotation = f1 + cdr1 + f2 + cdr2 + f3 + cdr3 + f4 + '\\n'\n",
    "                    output_line += annotation\n",
    "\n",
    "                    # Only increment when we're actually looking at a sequence:\n",
    "                    i += 1\n",
    "\n",
    "                output.write(output_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPADFAVYYCQQYGSSPSITFGQGTRLEIKR\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaa111111111111bbbbbbbbbbbbbbb2222222cccccccccccccccccccccccccccccccc3333333333ddddddddddd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotate('./pysster-data/humans.fasta','pysster-data/annotated-humans.fasta')\n",
    "annotate('./pysster-data/mice.fasta','pysster-data/annotated-mice.fasta')\n",
    "\n",
    "# Visualize the output of our annotation\n",
    "with open('./pysster-data/annotated-humans.fasta',\"r\") as input:\n",
    "    input.readline()\n",
    "    print(input.readline())\n",
    "    print(input.readline())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "from IPython.display import Image\n",
    "from pysster.Data import Data\n",
    "from pysster.Grid_Search import Grid_Search\n",
    "from pysster import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "All sequences must have the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-dbe1084115aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pysster-data/annotated-humans.fasta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./pysster-data/annotated-mice.fasta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ILVFMCAGPTSYWQNHEDKR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a1b2c3d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pysster/Data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, class_files, alphabet, structure_pwm)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All sequences must have the same length.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_val_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: All sequences must have the same length."
     ]
    }
   ],
   "source": [
    "data = Data([\"pysster-data/annotated-humans.fasta\", \"./pysster-data/annotated-mice.fasta\"], (\"ILVFMCAGPTSYWQNHEDKR\", \"a1b2c3d\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
